"""
游꿢 Cliente LLM Global - Inst칙ncia 칰nica compartilhada

Padr칚o module-level singleton (como c칩digo de refer칡ncia).

Inst칙ncias criadas UMA VEZ quando m칩dulo 칠 importado.
Todos os imports compartilham as MESMAS inst칙ncias.

Uso:
    from apps.game.llm_client import llm_client, embedding_client
    response = llm_client.invoke(...)
"""

import logging
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from django.conf import settings

logger = logging.getLogger("game.llm_client")

# 游꿢 Inst칙ncias globais criadas no import do m칩dulo
# Python garante execu칞칚o 칰nica - mais simples que singleton pattern

logger.info("[LLM Client] Criando inst칙ncia global de ChatGoogleGenerativeAI")
llm_client = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-lite",
    google_api_key=settings.GEMINI_API_KEY,
    temperature=0.7,
    max_output_tokens=2048,
    max_retries=0,  # 游뛂 Desabilita retries para evitar 4x mais chamadas no 429
)

logger.info("[LLM Client] Criando inst칙ncia global de GoogleGenerativeAIEmbeddings")
embedding_client = GoogleGenerativeAIEmbeddings(
    model="models/text-embedding-004",
    google_api_key=settings.GEMINI_API_KEY,
)
