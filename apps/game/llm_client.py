"""
游꿢 Cliente LLM Singleton - Inst칙ncia 칰nica compartilhada

Resolve problema de m칰ltiplas inst칙ncias causando erro 429.

Antes:
- Cada get_llm() criava nova inst칙ncia
- narrative_agent.py criava sua pr칩pria inst칙ncia
- embeddings criava sua pr칩pria inst칙ncia
= m칰ltiplas conex칫es HTTP, overhead, 429

Depois:
- UMA inst칙ncia global de ChatGoogleGenerativeAI
- UMA inst칙ncia global de GoogleGenerativeAIEmbeddings
- Todos os m칩dulos compartilham as mesmas inst칙ncias
= 1 conex칚o, menos overhead, sem 429
"""

import logging
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from django.conf import settings

logger = logging.getLogger("game.llm_client")

# 游꿢 Inst칙ncias singleton globais
_llm_instance = None
_embeddings_instance = None


def get_shared_llm(temperature: float = 0.7) -> ChatGoogleGenerativeAI:
    """
    Retorna inst칙ncia 칔NICA e compartilhada do ChatGoogleGenerativeAI.

    Todas as chamadas retornam a MESMA inst칙ncia, reduzindo overhead
    e evitando m칰ltiplas conex칫es simult칙neas.

    Args:
        temperature: Temperatura para gera칞칚o (padr칚o 0.7)

    Returns:
        Inst칙ncia singleton de ChatGoogleGenerativeAI
    """
    global _llm_instance

    if _llm_instance is None:
        logger.info("[LLM Client] Criando inst칙ncia singleton de ChatGoogleGenerativeAI")
        _llm_instance = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-lite",
            google_api_key=settings.GEMINI_API_KEY,
            temperature=temperature,
            max_output_tokens=2048,
        )

    return _llm_instance


def get_shared_embeddings() -> GoogleGenerativeAIEmbeddings:
    """
    Retorna inst칙ncia 칔NICA e compartilhada do GoogleGenerativeAIEmbeddings.

    Todas as chamadas retornam a MESMA inst칙ncia, reduzindo overhead
    e evitando m칰ltiplas conex칫es simult칙neas ao embedding API.

    Returns:
        Inst칙ncia singleton de GoogleGenerativeAIEmbeddings
    """
    global _embeddings_instance

    if _embeddings_instance is None:
        logger.info("[LLM Client] Criando inst칙ncia singleton de GoogleGenerativeAIEmbeddings")
        _embeddings_instance = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004",
            google_api_key=settings.GEMINI_API_KEY,
        )

    return _embeddings_instance


def reset_clients():
    """
    Reset das inst칙ncias singleton (칰til para testes).

    ATEN칂츾O: S칩 use em testes ou quando necess치rio reconfigurar.
    """
    global _llm_instance, _embeddings_instance

    logger.warning("[LLM Client] Resetando inst칙ncias singleton")
    _llm_instance = None
    _embeddings_instance = None
